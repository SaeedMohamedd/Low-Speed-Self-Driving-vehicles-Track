{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0eb098ad43327e1526f948aa18187ab2a0a1283cdb0b36f299cd41b25d0bdd229",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SHOW(img):\n",
    "    display(Image.fromarray(img));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('Lanes.mp4')\n",
    "out_video = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (1280,720))\n",
    "kernel_sharpen_2 = np.array([[-1, -1, -1],\n",
    "                             [-1,  9, -1],\n",
    "                             [-1, -1, -1]])\n",
    "\n",
    "pts1 = np.float32(\n",
    "        [\n",
    "            [50,  50], [368,  50],\n",
    "            [28, 387], [389, 390]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "pts2 = np.float32(\n",
    "        [\n",
    "            [0,   0], [300,  50],\n",
    "            [0, 300], [300, 300]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1 ,pts2)\n",
    "              \n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if  np.shape(frame) == (): # older numpy / py2\n",
    "        break\n",
    "    '''\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    s = hsv[:,:,1]\n",
    "    v = hsv[:,:,2]+50\n",
    "    v=255\n",
    "    s=255\n",
    "    '''\n",
    "    rows,cols = frame.shape[:2]\n",
    "    #print(rows,cols)\n",
    "    sharp_image_1 = cv2.filter2D(frame, -1, kernel_sharpen_2)\n",
    "    #img=cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    gray = cv2.cvtColor(sharp_image_1, cv2.COLOR_BGR2GRAY)\n",
    "    ret1, out = cv2.threshold(gray, 210, 255, cv2.THRESH_BINARY)\n",
    "    out_to_write = cv2.cvtColor(out, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    #dst = cv2.warpPerspective(out, M) \n",
    "    out_video.write(out_to_write)\n",
    "    cv2.imshow('frame',out)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "out_video.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'video_capture' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-11338070fa18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mvideo_capture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#ret, frame = cap.read()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'video_capture' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('Lanes.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow('Video', frame)\n",
    "        ret1, out = cv2.threshold(frame, 200, 255, cv2.THRESH_BINARY)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "#ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    #cv2.imshow('frame',out)\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "     #   break\n",
    "\n",
    "# When everything done, release the capture\n",
    "out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (500,1000))\n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Files/001.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "dst1 = cv2.filter2D(img,-1,kernel1)\n",
    "blur = cv2.blur(img,(9,9))\n",
    "gaussian = cv2.GaussianBlur(img, (9,9), 0)\n",
    "median = cv2.medianBlur(img, 9)\n",
    "bilateral = cv2.bilateralFilter(img,9,75,75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret1, out = cv2.threshold(img, low, high, cv2.THRESH_TRIANGLE)\n",
    "ret1, out = cv2.threshold(img, low, high, cv2.THRESH_TOZERO_INV)\n",
    "ret1, out = cv2.threshold(img, low, high, cv2.THRESH_TOZERO)\n",
    "ret1, out = cv2.threshold(img, low, high, cv2.THRESH_TRUNC)\n",
    "ret1, out = cv2.threshold(img, low, high, cv2.THRESH_BINARY_INV)\n",
    "ret1, out = cv2.threshold(img, low, high, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "out = cv2.adaptiveThreshold(img,\n",
    "                                    255,\n",
    "                                    cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                    cv2.THRESH_BINARY,\n",
    "                                    x,\n",
    "                                    y)\n",
    "out = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY,\n",
    "                                    x,\n",
    "                                    y)"
   ]
  }
 ]
}